# Build Process
### This document explains about how we are creating the disk images and the tarball

- Take a tagged release from Openshift installer and build it on a Linux machine.

```
$ git clone https://github.com/openshift/installer.git
$ git fetch --tags
$ git checkout v0.9.1
$ TAGS=libvirt hack/build.sh
```

- Run the installer binary (from the previous step) using libvirt provider on Linux using a dummy ssh key.

```
$ env TF_VAR_libvirt_master_memory=8192 TF_VAR_libvirt_master_vcpu=4 ./bin/openshift-install create cluster --dir=mycluster --log-level debug
[...]
? SSH Public Key dummy.pub
[...]
? Platform libvirt
? Libvirt Connection URI qemu+tcp://libvirt.default/system
[...]
? Base Domain tt.testing
? Cluster Name test1
? Pull Secret [? for help]  <Get it from try.openshift.com>
[...]
```

- Wait till all the nodes (master and worker) and pods are in healthy state (no crashbackloop or any other error).

```
$ kubectl get pods --all-namespaces
NAMESPACE                                                 NAME                                                              READY     STATUS      RESTARTS   AGE
kube-system                                               etcd-member-test1-master-0                                        1/1       Running     0          27m
openshift-apiserver-operator                              openshift-apiserver-operator-77756dfc66-942df                     1/1       Running     2          27m
openshift-apiserver                                       apiserver-sf68z                                                   1/1       Running     0          12m
openshift-cluster-api                                     cluster-autoscaler-operator-6855f55d94-29jkx                      1/1       Running     1          27m
openshift-cluster-api                                     clusterapi-manager-controllers-748cb8d66c-68c8w                   4/4       Running     0          22m
openshift-cluster-api                                     machine-api-operator-67f964b4d-tdnk5                              1/1       Running     0          27m
[...]
```

- Shutdown the master and worker node after setting it hostname.

Tarball content for the Linux host (using libvirt)
--------------------------------------------------

- Current disk images (`test1-master-0`, `test1-base`, `test1-worker-0-xxxx`) where `test1` in our cluster name.
    - These disk images have all container images part of the disk. So user do not need to fetch container images from the internet.
- Add the `kubeconfig` and `kubeadmin-password` which is generated by installer.
- Add `master-private-key` which can be used to `ssh` to master or worker node.
- Add `crc_<hypervisor name>.sh` shell script which can consume those bits and start cluster.


Tarball content for the Mac host (using VirtualBox)
---------------------------------------------------

- `test1-base` is the backing file for master and worker disk image.

```
$ qemu-img info test1-master-0
image: test1-master-0
file format: qcow2
virtual size: 16G (17179869184 bytes)
disk size: 6.2G
cluster_size: 65536
backing file: /var/lib/libvirt/images/test1-base
backing file format: qcow2
Format specific information:
    compat: 0.10
    refcount bits: 16
```

- First merge the snapshot and the backing file into standalone disk image both for master and worker.

```
$ cp test1-base new-master
$ qemu-img rebase -b new-master test1-master-0
$ qemu-img commit test1-master-0
Image committed.
$ qemu-img info new-master
image: new-master
file format: qcow2
virtual size: 16G (17179869184 bytes)
disk size: 6.1G
cluster_size: 65536
Format specific information:
    compat: 1.1
    lazy refcounts: false
    refcount bits: 16
    corrupt: false
```

- Convert disk images to `vmdk` using `qemu-img` to make it work for VirtualBox.

```
$ qemu-img convert -f qcow2 test1-master-0 -O vmdk test1-master-0.vmdk -p
$ qemu-img convert -f qcow2 test1-worker-0-xxx -O vmdk test1-worker-0-xxx.vmdk -p
```

- Add `coredns` binary and also `Corefile` and `test1-api` zone file to make local dns work.

